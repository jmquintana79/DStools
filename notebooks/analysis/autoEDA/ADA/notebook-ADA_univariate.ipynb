{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "invalid-imaging",
   "metadata": {},
   "source": [
    "# ADA (Automatic Data Analysis) - Univariate\n",
    "\n",
    "\n",
    "## Infraestructura\n",
    "\n",
    "- [x] Identicacion de tipo de datos de columnas, renombrado de columnas, factorizacion de valores categoricos.\n",
    "- [x] Creacion de lista de todas las combinaciones posibles de *queries* con variables categoricas para ser usadas por `df.query(squery)`.\n",
    "- [x] Estimacion de numero minimo de registros para que se pueda hacer un analisis estadistico con significancia suficente.\n",
    "- [ ] Transformacion de variables numericas en categoricas.\n",
    "\n",
    "## Analisis univariantes\n",
    "\n",
    "### num \n",
    "\n",
    "- [ ] es gaussiana.\n",
    "- [ ] hay separabilidad. \n",
    "    - [ ] univariante: clustering 1D, medidas de informacion.\n",
    "    - [ ] a traves de variable categorica.\n",
    "\n",
    "### cat\n",
    "\n",
    "- [ ] hay separabilidad. \n",
    "\n",
    "\n",
    "### num - num\n",
    "\n",
    "- [ ] correlacion.\n",
    "- [ ] F-test vs mutual information.\n",
    "- [ ] misma distribucion.\n",
    "\n",
    "\n",
    "### cat - cat\n",
    "\n",
    "- [ ] es misma distibucion.\n",
    "- [ ] tabla de contingencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plain-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287de09",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06d1e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALCULATE Z VALUE\n",
    "def get_z(confidence_level:float)->float:\n",
    "    \"\"\"\n",
    "    Calculate Z value for a given confidence level.\n",
    "    \n",
    "    confidence_level -- confidence level into percent. \n",
    "    return -- z value.\n",
    "    \"\"\"\n",
    "    return st.norm.ppf(1-(1-confidence_level/100.)/2)\n",
    "\n",
    "\n",
    "# CALCULATE THE SAMPLE SIZE\n",
    "def sample_size(population_size:int, confidence_level:float, confidence_interval:float):\n",
    "    \"\"\"\n",
    "    Calculate the sample size using the Cochranâ€™s Sample Size Formula.\n",
    "    \n",
    "    population_size -- the total population size.\n",
    "    confidence_level -- the seleceted confidence level in percent. \n",
    "    confidence_interval -- the selected confidence interval in percent.\n",
    "    return -- sample size with the correction for smaller population (no large).\n",
    "    \"\"\"\n",
    "    Z = 0.0\n",
    "    p = 0.5\n",
    "    e = confidence_interval/100.0\n",
    "    N = population_size\n",
    "    n_0 = 0.0\n",
    "    n = 0.0\n",
    "\n",
    "    # FIND THE NUM STD DEVIATIONS FOR THAT CONFIDENCE LEVEL\n",
    "    Z = get_z(confidence_level)\n",
    "\n",
    "    if Z == 0.0:\n",
    "        return -1\n",
    "\n",
    "    # CALC SAMPLE SIZE\n",
    "    n_0 = ((Z**2) * p * (1-p)) / (e**2)\n",
    "\n",
    "    # ADJUST SAMPLE SIZE FOR FINITE POPULATION\n",
    "    n = n_0 / (1 + ((n_0 - 1) / float(N)) )\n",
    "\n",
    "    return int(math.ceil(n)) # THE SAMPLE SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-thesaurus",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = load_iris()\n",
    "dataset.keys()\n",
    "# dataset to df\n",
    "raw = pd.DataFrame(dataset.data, columns = dataset.feature_names)\n",
    "raw['class'] = dataset.target\n",
    "dclass = dict()\n",
    "for i, ic in enumerate(dataset.target_names):\n",
    "    dclass[i] = ic\n",
    "raw['class'] = raw['class'].map(dclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-colorado",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c991795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Columns():\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.num = df.select_dtypes(include=['float64']).columns.values  # numerical columns\n",
    "        self.ord = df.select_dtypes(include=['int64']).columns.values    # numerical columns\n",
    "        self.cat = df.select_dtypes(include=['object']).columns.values   # categorical columns  \n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Categorical: {self.cat} \\nNumerical: {self.num} \\nOrdinal: {self.ord}' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a883c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical values conversion\n",
    "def conversion_categorical_values(df:pd.DataFrame, col:str)->(pd.DataFrame, dict):\n",
    "    # rename column\n",
    "    df.rename(columns = {col:'original'}, inplace = True)\n",
    "    # factorize\n",
    "    df[col] = pd.factorize(df['original'])[0]\n",
    "    # as str\n",
    "    df[col] = df[col].astype(str)\n",
    "    # create conversor\n",
    "    dcat = df[['original', col]].drop_duplicates().set_index(col).to_dict()['original']\n",
    "    # remove original column\n",
    "    df.drop('original', axis = 1, inplace = True)\n",
    "    # return\n",
    "    return (df, dcat)\n",
    "\n",
    "\n",
    "## simplify dataset\n",
    "def data_simplify(raw:pd.DataFrame)->(pd.DataFrame, dict, dict):\n",
    "    # copy \n",
    "    data = raw.copy()\n",
    "    # get columns\n",
    "    cols = Columns(data)\n",
    "    # initialize\n",
    "    dcols_name_to_alias = dict()\n",
    "    dcols_alias_to_name = dict()\n",
    "    # columns name converters: numerical\n",
    "    if len(cols.num)>0:\n",
    "        for i, ic in enumerate(cols.num):\n",
    "            dcols_name_to_alias[ic] = 'n{}'.format(i)\n",
    "            dcols_alias_to_name['n{}'.format(i)] = ic\n",
    "    # columns name converters: categorical\n",
    "    if len(cols.cat)>0:\n",
    "        for i, ic in enumerate(cols.cat):\n",
    "            dcols_name_to_alias[ic] = 'c{}'.format(i)\n",
    "            dcols_alias_to_name['c{}'.format(i)] = ic\n",
    "    # columns name converters: ordinal\n",
    "    if len(cols.ord)>0:\n",
    "        for i, ic in enumerate(cols.ord):\n",
    "            dcols_name_to_alias[ic] = 'o{}'.format(i)\n",
    "            dcols_alias_to_name['o{}'.format(i)] = ic\n",
    "    # rename columns\n",
    "    data.rename(columns = dcols_name_to_alias, inplace = True)\n",
    "    # get columns\n",
    "    cols_new = Columns(data)\n",
    "    # initialize\n",
    "    d_converter_cat_values = dict()\n",
    "    # loop of categorical columns\n",
    "    for col in cols_new.cat:\n",
    "        data, d_converter_cat_values[col] = conversion_categorical_values(data, col)\n",
    "    # return\n",
    "    return (data, dcols_alias_to_name, d_converter_cat_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b0e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset simplification\n",
    "data, dcols_alias_to_name, d_converter_cat_values = data_simplify(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc19ffd",
   "metadata": {},
   "source": [
    "# Queries combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c50be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more categorical variables [PARA TESTING]\n",
    "#data['c1'] = data['n1'].apply(lambda x: str(int(x)))\n",
    "#data['c2'] = data['n2'].apply(lambda x: str(int(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f95bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize final lists with single queries\n",
    "LIST_QUERIES = list()\n",
    "LIST_INDEX = list()\n",
    "# initialize\n",
    "n = 0\n",
    "cols = Columns(data)\n",
    "\n",
    "## variables combination\n",
    "\n",
    "# all possible combinations between variables\n",
    "per_cols = list()\n",
    "for i in range(1,len(cols.cat)+1,1):\n",
    "    per_cols += list(itertools.permutations(list(cols.cat),r=i))\n",
    "\n",
    "## singles queries\n",
    "\n",
    "# initialize\n",
    "dsingle_queries = dict()\n",
    "# get single queries\n",
    "for iper_cols in per_cols:\n",
    "    dsingle_queries[iper_cols[0]] = [f\"{iper_cols[0]} == '{cat}'\" for cat in sorted(list(data[iper_cols[0]].unique()))]\n",
    "\n",
    "# loop of single queries\n",
    "for c in dsingle_queries:\n",
    "    # add single queries\n",
    "    LIST_QUERIES += dsingle_queries[c]\n",
    "    # add their indexes\n",
    "    LIST_INDEX += [n for i in range(len(dsingle_queries[c]))]\n",
    "    # add to index\n",
    "    n+=1\n",
    "    \n",
    "## non single queries\n",
    "\n",
    "# get combination queries\n",
    "for iper_cols in [pc for pc in per_cols if len(pc)>1]:\n",
    "    # combine list of single queries\n",
    "    isingle_queries = list()\n",
    "    for c in iper_cols:\n",
    "        isingle_queries += dsingle_queries[c]\n",
    "    # get all possible combinations\n",
    "    comb = list(itertools.combinations(isingle_queries,r=len(iper_cols)))\n",
    "    # initialize\n",
    "    final_comb = list()\n",
    "    # loop of combinations\n",
    "    for ic in comb:\n",
    "        # create final query\n",
    "        icomb = ' & '.join(ic)\n",
    "        # append only necessary queries\n",
    "        if np.prod([c in icomb for c in iper_cols]):\n",
    "            final_comb.append(icomb)\n",
    "    # sort and append to the final list\n",
    "    final_comb = sorted(final_comb)\n",
    "    LIST_QUERIES += final_comb\n",
    "    \n",
    "    # estimate their indexes\n",
    "    l = [c.split(f' & {iper_cols[-1]}')[:-1] for c in final_comb]\n",
    "    ln = [n]\n",
    "    for i in range(len(l)-1):\n",
    "        if l[i] != l[i+1]:\n",
    "            n += 1\n",
    "        ln.append(n) \n",
    "    # add indexes to the final list\n",
    "    LIST_INDEX += ln\n",
    "    \n",
    "# store queries in a df\n",
    "dfqueries = pd.DataFrame({'query':LIST_QUERIES, 'number':LIST_INDEX})\n",
    "\n",
    "\n",
    "## add number of records per query\n",
    "\n",
    "# initialize\n",
    "LIST_SIZES = list()\n",
    "# loop of queries\n",
    "for squery in dfqueries['query'].values:\n",
    "    LIST_SIZES.append(len(data.query(squery)))\n",
    "# add new columnt\n",
    "dfqueries['sample_size'] = LIST_SIZES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222b33a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>number</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0 == '0'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0 == '1'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0 == '2'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  number  sample_size\n",
       "0  c0 == '0'       0           50\n",
       "1  c0 == '1'       0           50\n",
       "2  c0 == '2'       0           50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736a7bd",
   "metadata": {},
   "source": [
    "# Filter queries by min size of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423b9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE SIZE: 109 from 150\n",
      "Number of queries after filtering = 3\n"
     ]
    }
   ],
   "source": [
    "# estimate minimun size of sample\n",
    "population_sz = len(data)\n",
    "confidence_level = 95.0\n",
    "confidence_interval = 5.0\n",
    "n_min_sample_size = sample_size(population_sz, confidence_level, confidence_interval)\n",
    "print(\"SAMPLE SIZE: %d from %d\" %(n_min_sample_size, population_sz))\n",
    "# FOR TESTING\n",
    "n_min_sample_size = 50\n",
    "# filter queries\n",
    "dfqueries = dfqueries[dfqueries.sample_size>=n_min_sample_size]\n",
    "print(f'Number of queries after filtering = {len(dfqueries)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d2082b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>number</th>\n",
       "      <th>sample_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0 == '0'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c0 == '1'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0 == '2'</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  number  sample_size\n",
       "0  c0 == '0'       0           50\n",
       "1  c0 == '1'       0           50\n",
       "2  c0 == '2'       0           50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eae1ef",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da7d3823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables to remove of analising (in this case only numerical)\n",
    "cols_all = data.columns.tolist()\n",
    "cols_remove = [c for c in cols_all if c in squery]\n",
    "cols_num = [c for c in cols.num if not c in cols_remove]\n",
    "\n",
    "# get samples\n",
    "numbers_query_sets = sorted(list(dfqueries['number'].unique()))\n",
    "\n",
    "## get samples\n",
    "\n",
    "# loop of numbers of query sets\n",
    "number = numbers_query_sets[0] # JUAN\n",
    "\n",
    "# initialize samples\n",
    "dsamples = dict()\n",
    "# get queries for this set\n",
    "queries = dfqueries[dfqueries['number'] == number]['query'].tolist()\n",
    "# get samples per set\n",
    "for squery in queries:\n",
    "    dsamples[squery] = data.query(squery)[cols_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ebe4852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 == '0' 0.24599999999999997 0.1043264108459598\n",
      "c0 == '1' 1.3259999999999998 0.19576516544063705\n",
      "c0 == '2' 2.0260000000000002 0.2718896835115301\n"
     ]
    }
   ],
   "source": [
    "variable = 'n3'\n",
    "# loop of samples\n",
    "for k, dfsample in dsamples.items():\n",
    "    sample = dfsample[variable].values\n",
    "    print(k, np.mean(sample), np.std(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e312b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
