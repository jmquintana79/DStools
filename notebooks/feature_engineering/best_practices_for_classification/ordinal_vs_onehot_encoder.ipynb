{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ccf914-dabf-4aa8-8c70-b13644e58abb",
   "metadata": {},
   "source": [
    "# Titanic\n",
    "\n",
    "#### References\n",
    "\n",
    "- [Scikit-learn Pipelines with Titanic](https://jaketae.github.io/study/sklearn-pipeline/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "67523553-b4ea-4682-91d9-e406164d497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature_engine in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from feature_engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from feature_engine) (0.12.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from feature_engine) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from feature_engine) (1.21.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from feature_engine) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from pandas>=1.0.3->feature_engine) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.3->feature_engine) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature_engine) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from scikit-learn>=1.0.0->feature_engine) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/juan/miniconda3/envs/analysis/lib/python3.7/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "df21052c-e321-463e-89ab-8e7349b65101",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "58e4cb8e-40c6-44ee-a416-dde416fc3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.selection import DropFeatures\n",
    "from sklearn.impute import KNNImputer\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.encoding import OrdinalEncoder\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcdcd0-ed1a-40a9-af0e-7cf495c7039b",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "139f1d8a-183c-42c6-97de-460f04f82c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=False)\n",
    "# collect information\n",
    "data = dataset.frame\n",
    "col_x = dataset.feature_names\n",
    "col_y = dataset.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717dab6-18b0-435a-a075-4c9a20076c84",
   "metadata": {},
   "source": [
    "## data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "7900410b-4b87-4032-a007-9cdbb2675c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DATA FORMAT\n",
    "\n",
    "data['survived'] = data['survived'].apply(lambda x: True if x == '1' else False)\n",
    "data['survived'] = data['survived'].astype(bool)\n",
    "data['pclass'] = data['pclass'].astype(int)\n",
    "data['pclass'] = data['pclass'].astype(str)\n",
    "data['sex'] = data['sex'].astype(str)\n",
    "data['embarked'].fillna('C', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "## NEW FEATURES CREATION\n",
    "\n",
    "# family size\n",
    "data['family_size'] = data['parch'] + data['sibsp']\n",
    "data['family_size'] = data['family_size'].astype(int)\n",
    "# is alone according to family size\n",
    "data['is_alone'] = data['family_size'].apply(lambda x: \"0\" if x > 1 else \"1\")\n",
    "# title\n",
    "data['title'] =  data['name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n",
    "d_title_converter = {\n",
    "    'Miss':'Mrs',\n",
    "    'Mr':'Mr',\n",
    "    'Mrs':'Mrs'\n",
    "}\n",
    "data['title'] = data['title'].apply(lambda x: d_title_converter[x] if x in list(d_title_converter.keys()) else 'rare')\n",
    "# new feature columns list\n",
    "col_x = [c for c in data.columns if not c in col_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "a14b96bd-55d9-4fbf-a836-e77732133ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pipeline with common transformations\n",
    "pl_common = Pipeline(steps=[\n",
    "    ('drop_features', DropFeatures(features_to_drop=['boat', 'body', 'home.dest', 'cabin', 'ticket', 'parch', 'sibsp', 'name'])),\n",
    "    ('imputer_numerical', SklearnTransformerWrapper(transformer = KNNImputer(n_neighbors=5), variables = ['age', 'fare'])),\n",
    "    #('scaler', SklearnTransformerWrapper(transformer = RobustScaler(), variables = ['age', 'fare', 'family_size']))\n",
    "])\n",
    "\n",
    "\n",
    "# set pipeline with transformations for tree based algorithms (first option)\n",
    "pl_tree_1 = Pipeline(steps=[\n",
    "    ('encoding_categorical', OrdinalEncoder(encoding_method='ordered', variables=['sex', 'embarked', 'title', 'is_alone']))\n",
    "                           ])\n",
    "\n",
    "# set pipeline with transformations for tree based algorithms (second option)\n",
    "pl_tree_2 = Pipeline(steps=[\n",
    "    ('encoding_categorical', OneHotEncoder(drop_last_binary = True, variables=['embarked', 'sex', 'pclass', 'title', 'is_alone'])),\n",
    "    #('pca', PCA(n_components=5))\n",
    "                           ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9fc39-294d-4299-8e54-53d8d9173c01",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "ab8fc621-d394-4629-915e-44099eb55ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data\n",
    "X, y = data[col_x], data[col_y].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "c4d443d5-7ffd-45a9-9368-c657b472664a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7425190839694656, 0.06816417759726304)"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final pipeline\n",
    "pl1 = Pipeline(steps = [('pipeline_common', pl_common), \n",
    "                       ('pipeline_tree', pl_tree_1), \n",
    "                       ('classifier', RandomForestClassifier())\n",
    "                      ])\n",
    "\n",
    "# evaluation\n",
    "scores = cross_val_score(pl1, X, y, cv=10, scoring=\"accuracy\")\n",
    "# display\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "4cadc18b-58b4-402a-8274-4564cf2884cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7440458015267176, 0.07416300631934006)"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final pipeline\n",
    "pl2 = Pipeline(steps = [('pipeline_common', pl_common), \n",
    "                       ('pipeline_tree', pl_tree_2), \n",
    "                       ('classifier', RandomForestClassifier())\n",
    "                      ])\n",
    "\n",
    "# evaluation\n",
    "scores = cross_val_score(pl2, X, y, cv=10, scoring=\"accuracy\")\n",
    "# display\n",
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2135b-2ae9-4476-845f-09421ac8a0fd",
   "metadata": {},
   "source": [
    "#### Conclusiones\n",
    "\n",
    "- No existe mucha diferencia entre *OneHotEncoder* y *OrdinalEncoder* para algoritmos basados en arboles en el caso de que la cardinalidad no sea alta.\n",
    "- En el caso de que haya alta cardinalidad en variables categoricas si que el *OneHotEncoder* afectaria negativamente a algoritmos basados en arboles de decision.\n",
    "- Por tanto, **para algoritmos basados en arboles de decision lo mejor es usar el *OrdinalEncoder***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dcec2-ce0c-4296-9594-230ad2c6226d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
